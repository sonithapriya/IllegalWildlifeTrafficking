{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5634b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0ab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some urls are blocked from untrusted sites, the below code make python environment to trust every site\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39d6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    \n",
    "    f = open('site_urls.txt','r')\n",
    "    search_url = f.readlines()[30]\n",
    "    print(search_url)\n",
    "   \n",
    "    # path of chorme drive to run selenium\n",
    "    path = r'/Users/priyankasurapaneni/Documents/RA/chromedriver'\n",
    "    \n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    k = open('wildlife keywords.txt','r')\n",
    "    kw = k.readlines()\n",
    "    \n",
    "    for i in range(0,len(kw)):\n",
    "        print(i)\n",
    "        keyW = kw[i]\n",
    "        \n",
    "        driver.get(search_url)\n",
    "\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # search text box \n",
    "        box = driver.find_element_by_xpath('//*[@id=\"header-search\"]/input[2]')  \n",
    "        box.clear()\n",
    "        #sending the keyword\n",
    "        box.send_keys(keyW)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # try block if there are no ad results for the keyword it will continue with next keyword\n",
    "        try:\n",
    "            # collecting links of ad results\n",
    "            links = driver.find_element_by_xpath('//*[@id=\"product-list\"]')\n",
    "            sub_lnks = links.find_elements_by_tag_name('a')\n",
    "\n",
    "            lnks_lst = []\n",
    "\n",
    "            for lnk in sub_lnks:\n",
    "                lnks_lst.append(lnk.get_attribute('href'))\n",
    "            print(lnks_lst[0:3])\n",
    "\n",
    "            # making a directory like URL+Keyword_number , example 30_0 , 30_1,...\n",
    "            if lnks_lst:\n",
    "                if not os.path.exists(str(30)+'_'+str(i)):\n",
    "                    os.mkdir(str(30)+'_'+str(i))\n",
    "                    \n",
    "            #  iterating through ads results \n",
    "            for j in range(1,3):\n",
    "                driver.get(lnks_lst[j])\n",
    "                print(lnks_lst[j])\n",
    "                time.sleep(2)\n",
    "                # Title capturing\n",
    "                sub_txt = driver.find_element_by_xpath('//*[@id=\"product-title\"]/h1').text\n",
    "                \n",
    "                #making directory inside the above created directory like 0 means first ad, 1 for second ad....\n",
    "                if not os.path.exists(str(30)+'_'+str(i) +'/'+ str(j)):\n",
    "                    os.mkdir(str(30)+'_'+str(i) +'/'+ str(j))\n",
    "                # making dictionary\n",
    "                details = {\n",
    "                    'name' : sub_txt,\n",
    "                    'price' : driver.find_element_by_xpath('//*[@id=\"price\"]').text,\n",
    "                    'location': driver.find_element_by_xpath('//*[@id=\"seller-location\"]/ul/li').text,\n",
    "                    'details':None,\n",
    "                    'description' : driver.find_element_by_xpath('//*[@id=\"expandedDetailsContent\"]').get_attribute(\"innerText\"),\n",
    "                    'url' : lnks_lst[j]\n",
    "                }\n",
    "                \n",
    "                # writing the dictionary to text file like 0.txt for first ad ....\n",
    "                with open(str(30)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(details))\n",
    "                \n",
    "                # collecting image urls\n",
    "                image_lst = []\n",
    "                elem1 = driver.find_element_by_xpath('//*[@id=\"product-image-container\"]')\n",
    "                sub = elem1.find_elements_by_tag_name('img')\n",
    "                for k,l in enumerate(sub):\n",
    "                    src = l.get_attribute('src')\n",
    "                    image_lst.append(src)\n",
    "                    print(src)\n",
    "                    # collecting images and saving it inside the above created directory like 0_0.jpg for first ad first image\n",
    "                    # 0_1.jpg for first ad second image ...\n",
    "                    if src != None:\n",
    "                        urllib.request.urlretrieve(str(src), os.path.join(str(30)+'_'+str(i), str(j), str(j)+'_'+str(k)+'.jpg'))\n",
    "                # writing image urls to text file like 0_imgs.txt for first ad ....\n",
    "                with open(str(30)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '_imgs.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(image_lst)) \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b5a062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ecrater.com/filter.php?a=1&keywords=[KW]&view=list&sort=price_desc\n",
      "\n",
      "0\n",
      "['https://www.ecrater.com/p/40747526/plant-30-mature-with-flowers-aranto-alligator?keywords=alligator', 'https://www.ecrater.com/p/40747526/plant-30-mature-with-flowers-aranto-alligator?keywords=alligator', 'http://enternity.ecrater.com/']\n",
      "https://www.ecrater.com/p/40747526/plant-30-mature-with-flowers-aranto-alligator?keywords=alligator\n",
      "https://s.ecrater.com/stores/545250/620c465190e35_545250b.jpg\n",
      "http://enternity.ecrater.com/\n",
      "1\n",
      "['https://www.ecrater.com/p/19649351/gelpi-retractr-volkman-bone-curette?keywords=alligator%2Bbone', 'https://www.ecrater.com/p/19649351/gelpi-retractr-volkman-bone-curette?keywords=alligator%2Bbone', 'http://oneclass.ecrater.com/']\n",
      "https://www.ecrater.com/p/19649351/gelpi-retractr-volkman-bone-curette?keywords=alligator%2Bbone\n",
      "https://s.ecrater.com/stores/275853/533278c4a1996_275853b.jpg\n",
      "https://s.ecrater.com/stores/275853/533278c4a1996_275853s.jpg\n",
      "https://s.ecrater.com/stores/275853/533278c53d00b_275853s.jpg\n",
      "http://oneclass.ecrater.com/\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    download_images()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33c612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
