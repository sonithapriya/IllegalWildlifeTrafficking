{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5634b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a0ab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some urls are blocked from untrusted sites, the below code make python environment to trust every site\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39d6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    \n",
    "    f = open('site_urls.txt','r')\n",
    "    search_url = f.readlines()[1]\n",
    "    search_url = search_url.replace('uk','us')\n",
    "    print(search_url)\n",
    "    \n",
    "   \n",
    "    # path of chorme drive to run selenium\n",
    "    path = r'chromedriver'\n",
    "    \n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    k = open('wildlife keywords.txt','r')\n",
    "    kw = k.readlines()\n",
    "\n",
    "    # Urllib header assigning \n",
    "    opener = urllib.request.build_opener()\n",
    "    opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "    urllib.request.install_opener(opener)\n",
    "    \n",
    "    for i in range(0,len(kw)):\n",
    "        print(i)\n",
    "        keyW = kw[i]\n",
    "        \n",
    "        driver.get(search_url)\n",
    "\n",
    "        #search text box \n",
    "        box = driver.find_element_by_xpath('//*[@id=\"keywordbox\"]/input[3]')\n",
    "        box.clear()\n",
    "        \n",
    "        #sending the keyword\n",
    "        box.send_keys(keyW)\n",
    "        \n",
    "        # try block if there are no ad results for the keyword it will continue with next keyword\n",
    "        try:\n",
    "            # collecting links of ad results\n",
    "            links = driver.find_element_by_xpath('//*[@id=\"EBIDRIGHT\"]/div[8]/table/tbody')\n",
    "            sub_lnks = links.find_elements_by_xpath('.//td[1]/a')\n",
    "\n",
    "            lnks_lst = []\n",
    "\n",
    "            for lnk in sub_lnks:\n",
    "                lnks_lst.append(lnk.get_attribute('href'))\n",
    "\n",
    "            # making a directory like URL+Keyword_number , example 1_0 , 1_1,...\n",
    "            if lnks_lst:\n",
    "                if not os.path.exists(str(1)+'_'+str(i)):\n",
    "                    os.mkdir(str(1)+'_'+str(i))\n",
    "                    \n",
    "            #  iterating through ads results \n",
    "            for j in range(len(lnks_lst)):\n",
    "                print(lnks_lst[j])\n",
    "                driver.get(lnks_lst[j])\n",
    "                time.sleep(2)\n",
    "                # Title capturing\n",
    "                sub_txt = driver.find_element_by_xpath('//*[@id=\"listingTitle\"]').text\n",
    "                \n",
    "                #making directory inside the above created directory like 0 means first ad, 1 for second ad....\n",
    "                if not os.path.exists(str(1)+'_'+str(i) +'/'+ str(j)):\n",
    "                    os.mkdir(str(1)+'_'+str(i) +'/'+ str(j))\n",
    "                    \n",
    "                # making dictionary\n",
    "                details = {\n",
    "                    'name' : sub_txt,\n",
    "                    'price' : driver.find_element_by_xpath('//*[@id=\"idpright\"]/div/div[2]/div[1]/div[1]/ins').text,\n",
    "                    'location': driver.find_element_by_xpath('//*[@id=\"meetseller\"]/div[2]/div[2]/div[6]').text,\n",
    "                    'details': driver.find_element_by_xpath('//*[@id=\"meetseller\"]/div[2]/div[2]').get_attribute(\"innerText\"),\n",
    "                    'description' : driver.find_element_by_xpath('//*[@id=\"infoPanel\"]').get_attribute(\"innerText\"),\n",
    "                    'url' : lnks_lst[j]\n",
    "                }\n",
    "                \n",
    "                # writing the dictionary to text file like 0.txt for first ad ....\n",
    "                with open(str(1)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(details))\n",
    "                        \n",
    "                # collecting image urls\n",
    "                image_lst = []\n",
    "                elem1 = driver.find_element_by_xpath('//*[@id=\"idpleft\"]/div[1]/div/div/div')\n",
    "                sub = elem1.find_elements_by_tag_name('a')\n",
    "                for k,l in enumerate(sub):\n",
    "                    href = l.get_attribute('href')\n",
    "                    image_lst.append(href)\n",
    "                    print(href)\n",
    "                    # collecting images and saving it inside the above created directory like 0_0.jpg for first ad first image\n",
    "                    # 0_1.jpg for first ad second image ...\n",
    "                    if href != None:\n",
    "                        urllib.request.urlretrieve(str(href), os.path.join(str(1)+'_'+str(i), str(j), str(j)+'_'+str(k)+'.jpg'))\n",
    "                # writing image urls to text file like 0_imgs.txt for first ad ....\n",
    "                with open(str(1)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '_imgs.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(image_lst))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b5a062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ebid.net/us/perl/main.cgi?mo=search&words=[KW]&categoryid=&fulltext=&type=keyword&type1=a&type2=a&countryid=&used=&price1=&price2=&sfeedback=&near_me=&pcode=&force_keyword=&adult=&categoryonly=&category2=&useronly=&useronly_username=&view_format=gallery&sort=2-1\n",
      "\n",
      "597\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    download_images()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc822b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
