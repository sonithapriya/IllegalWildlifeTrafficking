{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5634b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0ab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some urls are blocked from untrusted sites, the below code make python environment to trust every site\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39d6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    \n",
    "    f = open('site_urls.txt','r')\n",
    "    search_url = f.readlines()[19]\n",
    "    print(search_url)\n",
    "   \n",
    "    # path of chorme drive to run selenium\n",
    "    path = r'chromedriver'\n",
    "    \n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    k = open('wildlife keywords.txt','r')\n",
    "    kw = k.readlines()\n",
    "    \n",
    "    for i in range(0,len(kw)):\n",
    "        print(i)\n",
    "        keyW = kw[i]\n",
    "        \n",
    "        driver.get(search_url)\n",
    "        \n",
    "        # X mark clicking in search text box\n",
    "        driver.find_element_by_xpath('/html/body/div/div/div[1]/div/div[2]/div/a').click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # search text box\n",
    "        box = driver.find_element_by_xpath('//*[@id=\"search\"]')  \n",
    "        #sending the keyword\n",
    "        box.send_keys(keyW)\n",
    "        box.send_keys(Keys.ENTER)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # try block if there are no ad results for the keyword it will continue with next keyword\n",
    "        try:\n",
    "            # collecting links of ad results\n",
    "            links = driver.find_element_by_xpath('/html/body/div/div/div[5]/div/div[1]/div[1]/div[4]/ul')\n",
    "            sub_lnks = links.find_elements_by_tag_name('a')\n",
    "\n",
    "            lnks_lst = []\n",
    "\n",
    "            for lnk in sub_lnks:\n",
    "                lnks_lst.append(lnk.get_attribute('href'))\n",
    "            print(lnks_lst[2:4])\n",
    "\n",
    "            # making a directory like URL+Keyword_number , example 19_0 , 19_1,...\n",
    "            if lnks_lst:\n",
    "                if not os.path.exists(str(19)+'_'+str(i)):\n",
    "                    os.mkdir(str(19)+'_'+str(i))\n",
    "                    \n",
    "            #  iterating through ads results  \n",
    "            for j in range(2,3):\n",
    "                driver.get(lnks_lst[j])\n",
    "                print(lnks_lst[j])\n",
    "                time.sleep(2)\n",
    "                # Title capturing \n",
    "                sub_txt = driver.find_element_by_xpath('//*[@id=\"product_addtocart_form\"]/div[2]/div[2]/div/div[1]/div[1]/h1').text\n",
    "                #making directory inside the above created directory like 0 means first ad, 1 for second ad....\n",
    "                if not os.path.exists(str(19)+'_'+str(i) +'/'+ str(j)):\n",
    "                    os.mkdir(str(19)+'_'+str(i) +'/'+ str(j))\n",
    "                # making dictionary\n",
    "                details = {\n",
    "                    'name' : sub_txt,\n",
    "                    'price' : driver.find_element_by_xpath('//*[@id=\"old-price-9347\"]').text,\n",
    "                    'location': None,\n",
    "                    'details': driver.find_element_by_xpath('//*[@id=\"product_addtocart_form\"]/div[2]/div[2]/div/div[1]/div[2]/div').get_attribute(\"innerText\"),\n",
    "                    'description' : None,\n",
    "                    'url' : lnks_lst[j]\n",
    "                }\n",
    "                # writing the dictionary to text file like 0.txt for first ad ....\n",
    "                with open(str(19)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(details))\n",
    "                \n",
    "                # collecting image urls\n",
    "                image_lst = []\n",
    "                elem1 = driver.find_element_by_xpath('//*[@id=\"product_addtocart_form\"]/div[2]/div[1]/div')\n",
    "                sub = elem1.find_elements_by_tag_name('img')\n",
    "                for k,l in enumerate(sub):\n",
    "                    src = l.get_attribute('src')\n",
    "                    image_lst.append(src)\n",
    "                    print(src)\n",
    "                    # collecting images and saving it inside the above created directory like 0_0.jpg for first ad first image\n",
    "                    # 0_1.jpg for first ad second image ...\n",
    "                    if src != None:\n",
    "                        urllib.request.urlretrieve(str(src), os.path.join(str(19)+'_'+str(i), str(j), str(j)+'_'+str(k)+'.jpg'))\n",
    "                # writing image urls to text file like 0_imgs.txt for first ad ....\n",
    "                with open(str(19)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '_imgs.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(image_lst)) \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b5a062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.glacierwear.com/catalogsearch/result/index/?ajaxcatalog=true&dir=desc&limit=24&order=price&q=[KW]\n",
      "\n",
      "0\n",
      "['https://www.glacierwear.com/quickview/index/view/id/9347', 'https://www.glacierwear.com/tiger-eye-beads-1061.html']\n",
      "https://www.glacierwear.com/quickview/index/view/id/9347\n",
      "https://www.glacierwear.com/media/catalog/product/cache/1/thumbnail/600x/17f82f742ffe127f42dca9de82fb58b1/1/0/1061.jpg\n",
      "1\n",
      "['https://www.glacierwear.com/quickview/index/view/id/9347', 'https://www.glacierwear.com/tiger-eye-beads-1061.html']\n",
      "https://www.glacierwear.com/quickview/index/view/id/9347\n",
      "https://www.glacierwear.com/media/catalog/product/cache/1/thumbnail/600x/17f82f742ffe127f42dca9de82fb58b1/1/0/1061.jpg\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    download_images()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33c612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
