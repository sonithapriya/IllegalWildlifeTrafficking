{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5634b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time \n",
    "import os\n",
    "import json\n",
    "import urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0ab82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some urls are blocked from untrusted sites, the below code make python environment to trust every site\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b39d6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images():\n",
    "    \n",
    "    f = open('site_urls.txt','r')\n",
    "    search_url = f.readlines()[5]\n",
    "    print(search_url)\n",
    "   \n",
    "    # path of chorme drive to run selenium\n",
    "    path = r'chromedriver'\n",
    "    \n",
    "    driver = webdriver.Chrome(path)\n",
    "    \n",
    "    k = open('wildlife keywords.txt','r')\n",
    "    kw = k.readlines()\n",
    "    \n",
    "    for i in range(0,len(kw)):\n",
    "        print(i)\n",
    "        keyW = kw[i]\n",
    "        \n",
    "        driver.get(search_url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # X mark clicking in search text box\n",
    "        driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/ng-component/tm-search-header/div[1]/div/tm-refine-header/div[1]/tm-refine-keywords/div/form/tg-input-container/label[2]/span[3]/button').click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # search text box \n",
    "        box = driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/ng-component/tm-search-header/div[1]/div/tm-refine-header/div[1]/tm-refine-keywords/div/form/tg-input-container/label[2]/span[2]/input')    \n",
    "        #sending the keyword\n",
    "        box.send_keys(keyW)\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # try block if there are no ad results for the keyword it will continue with next keyword\n",
    "        try:\n",
    "            # collecting links of ad results\n",
    "            links = driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/ng-component/div/div/tg-row/tg-col/tm-search-results/div/div[2]/tm-potential-r18-content/div/tg-row')\n",
    "            sub_lnks = links.find_elements_by_tag_name('a')\n",
    "\n",
    "            lnks_lst = []\n",
    "\n",
    "            for lnk in sub_lnks:\n",
    "                lnks_lst.append(lnk.get_attribute('href'))\n",
    "            \n",
    "             # making a directory like URL+Keyword_number , example 5_0 , 5_1,...\n",
    "            if lnks_lst:\n",
    "                if not os.path.exists(str(5)+'_'+str(i)):\n",
    "                    os.mkdir(str(5)+'_'+str(i))\n",
    "                    \n",
    "            #  iterating through ads results \n",
    "            for j in range(1,3):\n",
    "                driver.get(lnks_lst[j])\n",
    "                time.sleep(10)\n",
    "                # Title capturing\n",
    "                sub_txt = driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/tm-marketplace-listing/div/div[1]/tm-potential-r18-content/div/tg-row[1]/tg-col[2]/tm-marketplace-buyer-options/h1').text\n",
    "                #making directory inside the above created directory like 0 means first ad, 1 for second ad....\n",
    "                if not os.path.exists(str(5)+'_'+str(i) +'/'+ str(j)):\n",
    "                    os.mkdir(str(5)+'_'+str(i) +'/'+ str(j))\n",
    "                # making dictionary\n",
    "                details = {\n",
    "                    'name' : sub_txt,\n",
    "                    'price' : driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/tm-marketplace-listing/div/div[1]/tm-potential-r18-content/div/tg-row[1]/tg-col[2]/tm-marketplace-buyer-options/div/tm-buy-now-box/tg-box2/div/div[1]/p[2]/strong').text,\n",
    "                    'location': driver.find_element_by_xpath('//*[@id=\"seller-details-section\"]/tm-marketplace-listing-seller-details/tg-row/tg-col[2]/tm-member-summary/section/div[3]/tm-core-seller-details/tg-rack/tg-rack-item[1]/div/div/tg-rack-item-secondary').text,\n",
    "                    'details': driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/tm-marketplace-listing/div/div[1]/tm-potential-r18-content/div/tg-row[1]/tg-col[1]/tm-marketplace-listing-body/div/div[2]').get_attribute(\"innerText\"),\n",
    "                    'description' : driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/tm-marketplace-listing/div/div[1]/tm-potential-r18-content/div/tg-row[1]/tg-col[1]/tm-marketplace-listing-body/div/div[1]').get_attribute(\"innerText\"),\n",
    "                    'url' : lnks_lst[j]\n",
    "                }\n",
    "                # writing the dictionary to text file like 0.txt for first ad ....\n",
    "                with open(str(5)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(details))\n",
    "                # collecting image urls\n",
    "                image_lst = []\n",
    "                elem1 = driver.find_element_by_xpath('/html/body/tm-root/div[1]/main/div/tm-marketplace-listing/div/div[1]/tm-potential-r18-content/div/tg-row[1]/tg-col[1]/tm-marketplace-listing-photos/tg-content-slider2/div/div[2]/div/div/div')\n",
    "                sub = elem1.find_elements_by_tag_name('tg-aspect-ratio')\n",
    "                for k,l in enumerate(sub):\n",
    "\n",
    "                        urls = l.get_attribute('style');\n",
    "                        src = urls.split('\"')[1].replace('thumb','full')\n",
    "                        print(src)\n",
    "                        image_lst.append(src)\n",
    "                        \n",
    "                        # collecting images and saving it inside the above created directory like 0_0.jpg for first ad first image\n",
    "                        # 0_1.jpg for first ad second image ...\n",
    "                        if src != None:\n",
    "                            urllib.request.urlretrieve(str(src), os.path.join(str(5)+'_'+str(i), str(j), str(j)+'_'+str(k)+'.jpg'))\n",
    "                # writing image urls to text file like 0_imgs.txt for first ad ....\n",
    "                with open(str(5)+'_'+str(i) +'/'+ str(j) + '/' + str(j) + '_imgs.txt', 'w') as tfile:\n",
    "                     tfile.write(json.dumps(image_lst))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11255674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    download_images()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
